{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# FastText 학습"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# mecab 사용 (에러가 난다면 Okt로 사용)\n",
    "from konlpy.tag import Mecab\n",
    "mecab=Mecab()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# 데이터 토큰화 (말뭉치 데이터 사용)\n",
    "import json\n",
    "def make_token(input_file, output_file):\n",
    "    mecab=Mecab()\n",
    "    token_file=open(output_file, 'w', encoding='utf-8')\n",
    "    list=[]\n",
    "\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        text=f.readlines()\n",
    "        \n",
    "\n",
    "        for i in range(0, len(text)):\n",
    "            sentence=text[i].strip()\n",
    "            morphs=mecab.morphs(sentence)\n",
    "            list.append(morphs)\n",
    "    print('finish')\n",
    "    my_json_string=json.dumps(list,ensure_ascii=False)\n",
    "    token_file.write(my_json_string)\n",
    "\n",
    "# make_token(토큰화 할 데이터 경로, 토큰화 된 데이터 경로)\n",
    "make_token('data.txt', 'token_data.txt')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# 토큰화된 데이터 학습\n",
    "from gensim.models import FastText\n",
    "with open('token_data.txt','r',encoding='utf-8') as f:\n",
    "    text=f.readlines()\n",
    "    data=json.loads(text[0])\n",
    "\n",
    "embedding=FastText(data, size=100, window=7, negative=3, min_count=5) \n",
    "# 모델 저장\n",
    "embedding.save('model/fasttext.model')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "len(data)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "728677"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# FastText 사용"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "\n",
    "from gensim.models import FastText\n",
    "model=FastText.load('model/fasttext.model')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import re\n",
    "\n",
    "def test(s):\n",
    "    hangul = re.compile('[^ ㄱ-ㅣ가-힣+]')\n",
    "    result = hangul.sub('', s) \n",
    "    return result\n",
    "\n",
    "word='존경' # 명사 또는 형용사만 가능 \n",
    "for i in model.most_similar(word):\n",
    "    if test(i[0]):\n",
    "        print(i[0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-4-ddbd91bc0519>:9: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  for i in model.most_similar(word):\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "존경어\n",
      "존경각\n",
      "칭송\n",
      "총애\n",
      "쇳돌\n",
      "흠모\n",
      "존경심\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}